{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2878d51c-461d-4d76-8805-70ecb50c7195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "372a8b17-f985-4e88-a734-0d11b6a29312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.model_selection import KFold,GroupKFold,StratifiedKFold,StratifiedGroupKFold\n",
    "import warnings\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from copy import deepcopy\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "import regex as re\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7806a91-2936-4a9e-a7f2-c1257fbb41fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CATS = ['activations', 'text_change']\n",
    "NUMS = ['action_time', 'cursor_position', 'word_count', 'elapsed_time_diff_1', \"down_time\" ]\n",
    "\n",
    "NUMS_1 = [ \"elapsed_time_diff_2\",\n",
    "            \"elapsed_time_diff_3\",\n",
    "            \"elapsed_time_diff_5\",\n",
    "            \"elapsed_time_diff_10\",\n",
    "            \"elapsed_time_diff_20\",\n",
    "            \"elapsed_time_diff_50\",\n",
    "            \"cursor_position_diff_1\",\n",
    "            \"cursor_position_diff_2\",\n",
    "            \"cursor_position_diff_3\",\n",
    "            \"cursor_position_diff_5\",\n",
    "            \"cursor_position_diff_10\",\n",
    "            \"cursor_position_diff_20\",\n",
    "            \"cursor_position_diff_50\",\n",
    "            \"word_count_diff_1\",\n",
    "            \"word_count_diff_2\",\n",
    "            \"word_count_diff_3\",\n",
    "            \"word_count_diff_5\",\n",
    "            \"word_count_diff_10\",\n",
    "            \"word_count_diff_20\",\n",
    "            \"word_count_diff_50\",\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "NUMS += NUMS_1\n",
    "name_feature = ['Nonproduction',\n",
    "                 'Input',\n",
    "                 'Remove/Cut',\n",
    "                 'Replace',\n",
    "                 'Move',\n",
    "                 'Paste',\n",
    "               ]\n",
    "\n",
    "text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "\n",
    "punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/',\n",
    "                '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+']\n",
    "\n",
    "down_event_feature = [\n",
    "            'Dead','F3','{','Meta','F15','ArrowDown','z','F6','Pause','S','\\x80',')','u','Cancel','Backspace','End','¡','MediaTrackNext','/','Tab','C','i','Process','F11','Home','~','%','1','q','F','s','5','Clear','l','OS','h','o','.','2','n','Control','*','Escape','#','`','â\\x80\\x93','Â´','MediaTrackPrevious','Alt','Ä±','a','@','PageUp','A','NumLock','ModeChange',',','^','PageDown','ContextMenu','F12','F2','Unknownclick','b','\\x9b','-','\"',\"'\",';','Delete','F1','$','T','0','CapsLock','M','ArrowRight','Ë\\x86','AudioVolumeDown','?','p','Insert','\\x96','y','w','AudioVolumeUp','Enter','Leftclick','V','¿','MediaPlayPause','}','AltGraph','_','I',':','AudioVolumeMute','Rightclick','>','ArrowLeft','c','Middleclick','(','ScrollLock','r','ArrowUp','Shift','Unidentified','&','|','g','!','v','F10','x','+','=','j','t','d','e','\\x97','Space','Å\\x9f','m','f','\\\\','ä'\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "down_event_feature = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', 'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "pasue_gaps = [8]\n",
    "\n",
    "up_event_feature = [\n",
    "    'AudioVolumeDown','h','MediaTrackNext','ArrowRight','l','Ë\\x86','S',\"'\",'f','Â´','>','F12','~',']','Space','Escape','r','o','F10','Leftclick','[','g','e','=','¿','T','-','MediaPlayPause','k','Backspace','Enter','C','{','i','AudioVolumeUp','MediaTrackPrevious','<','`','F15','q','F1','Å\\x9f','Delete','AltGraph','(','^','Process','0','CapsLock',')','Alt','ArrowUp','ScrollLock','Clear','c','ModeChange','_','|','ArrowDown','Ä±','+','PageUp','\\x80','NumLock','\"','Middleclick','M','Cancel','#',':','â\\x80\\x93','a','ä','Home','\\x9b','1','V','Unidentified','b','\\\\','Insert','Shift','Rightclick','\\x97','?','F11','5','Unknownclick','2','n','\\x96','%','t','$','j','ContextMenu','p','y','End','d','@','m','v','Pause','.','!','OS','ArrowLeft','PageDown','s','Control','F3','}','F6','w','&','Dead','¡','u','x','A','Meta',',','z','/','*',';','Tab','AudioVolumeMute','F2'\n",
    "    ]\n",
    "\n",
    "up_event_feature = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', 'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "373df3a2-f1a0-44f4-9162-f2402b1a965f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_act(act_name):\n",
    "    if act_name.startswith(\"Move\"):\n",
    "        return \"Move\"\n",
    "    else:\n",
    "        return act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85d47112-0cc6-4257-80a3-df4a4ef12f6c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    pl.col(\"action_time\").cast(pl.Float32),\n",
    "    pl.col(\"cursor_position\").cast(pl.Float32),\n",
    "    ((pl.col(\"cursor_position\") - pl.col(\"cursor_position\").shift(1)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"cursor_position_diff\")),\n",
    "    pl.col(\"word_count\").cast(pl.Float32),\n",
    "    pl.col(\"activity\").apply(rename_act).alias(\"activations\"),\n",
    "    \n",
    "    ((pl.col(\"down_time\") - pl.col(\"up_time\").shift(1)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"elapsed_time_diff_1\")),\n",
    "    ((pl.col(\"down_time\") - pl.col(\"up_time\").shift(2)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"elapsed_time_diff_2\")),\n",
    "    ((pl.col(\"down_time\") - pl.col(\"up_time\").shift(3)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"elapsed_time_diff_3\")),\n",
    "    ((pl.col(\"down_time\") - pl.col(\"up_time\").shift(5)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"elapsed_time_diff_5\")),\n",
    "    ((pl.col(\"down_time\") - pl.col(\"up_time\").shift(10)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"elapsed_time_diff_10\")),\n",
    "    ((pl.col(\"down_time\") - pl.col(\"up_time\").shift(20)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"elapsed_time_diff_20\")),\n",
    "    ((pl.col(\"down_time\") - pl.col(\"up_time\").shift(50)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"elapsed_time_diff_50\")),\n",
    "    \n",
    "    ((pl.col(\"cursor_position\") - pl.col(\"cursor_position\").shift(1)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"cursor_position_diff_1\")),\n",
    "    ((pl.col(\"cursor_position\") - pl.col(\"cursor_position\").shift(2)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"cursor_position_diff_2\")),\n",
    "    ((pl.col(\"cursor_position\") - pl.col(\"cursor_position\").shift(3)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"cursor_position_diff_3\")),\n",
    "    ((pl.col(\"cursor_position\") - pl.col(\"cursor_position\").shift(5)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"cursor_position_diff_5\")),\n",
    "    ((pl.col(\"cursor_position\") - pl.col(\"cursor_position\").shift(10)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"cursor_position_diff_10\")),\n",
    "    ((pl.col(\"cursor_position\") - pl.col(\"cursor_position\").shift(20)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"cursor_position_diff_20\")),\n",
    "    ((pl.col(\"cursor_position\") - pl.col(\"cursor_position\").shift(50)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"cursor_position_diff_50\")),\n",
    "\n",
    "    ((pl.col(\"word_count\") - pl.col(\"word_count\").shift(1)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"word_count_diff_1\")),\n",
    "    ((pl.col(\"word_count\") - pl.col(\"word_count\").shift(2)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"word_count_diff_2\")),\n",
    "    ((pl.col(\"word_count\") - pl.col(\"word_count\").shift(3)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"word_count_diff_3\")),\n",
    "    ((pl.col(\"word_count\") - pl.col(\"word_count\").shift(5)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"word_count_diff_5\")),\n",
    "    ((pl.col(\"word_count\") - pl.col(\"word_count\").shift(10)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"word_count_diff_10\")),\n",
    "    ((pl.col(\"word_count\") - pl.col(\"word_count\").shift(20)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"word_count_diff_20\")),\n",
    "    ((pl.col(\"word_count\") - pl.col(\"word_count\").shift(50)).fill_null(0).clip(-1e9, 1e9).over(\n",
    "        [\"id\"]).alias(\"word_count_diff_50\")),\n",
    "    \n",
    "    (pl.col('word_count').max()/pl.col('action_time').max()/1000).alias('word_count_pre_step'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c14e3fa4-75a9-48ac-ba93-a15257965a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = (pl.read_csv(\"train_logs.csv\")\n",
    "      .with_columns(columns)\n",
    "      .drop([\"activity\"])\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089ce2d-5e00-4ee2-aaf0-5652c68a8f83",
   "metadata": {},
   "source": [
    "## build text feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f05f837-a95b-4a54-a990-c252d0022f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_df = pd.read_csv('corpus.csv')\n",
    "# corpus = text_df['text'].tolist()\n",
    "# pipe = Pipeline([('count', CountVectorizer()),\n",
    "#                  ('tfid', TfidfTransformer())]).fit(corpus)\n",
    "# text_feature = pipe.transform(corpus).toarray()\n",
    "# text_feature_df = pd.DataFrame(text_feature, columns=[f'text_features_{i}' for i in range(text_feature.shape[1])])\n",
    "# text_feature_df['id'] = tmp_df['id']\n",
    "# text_feature_df = text_feature_df.set_index('id')\n",
    "# joblib.dump(pipe, './xgb_5fold/pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b7565fb-0b4e-4e11-bfc4-817181554386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_result = pd.read_csv('bert_predict.csv').set_index('id')[['bert']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff76234e-bf05-4adf-a062-df2136b2c63f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = joblib.load('./xgb_5fold/pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f1f7334-568a-4d6d-aebc-afb86427ae73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载预训练模型\n",
    "\n",
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc_dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "        #feature = F.normalize(feature, p=2, dim=1)\n",
    "        return feature\n",
    "\n",
    "    \n",
    "# model_name = './pretrained_model'\n",
    "# device = 'cuda'\n",
    "# model = CustomModel(model_name)\n",
    "# model.to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = self.texts[item]\n",
    "       \n",
    "        inputs = tokenizer(text,\n",
    "                           max_length=256,\n",
    "                           pad_to_max_length=True,\n",
    "                           add_special_tokens=True,\n",
    "                           return_offsets_mapping=False)\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return inputs\n",
    "\n",
    "def get_model_feature(model, texts):\n",
    "    feature_outs_all = []\n",
    "    test_dataset = TestDataset(texts)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=32,\n",
    "                             shuffle=False,\n",
    "                             collate_fn=DataCollatorWithPadding(tokenizer=tokenizer, padding='longest'),\n",
    "                             num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tqdm(test_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            feature_outs = model(inputs)\n",
    "            feature_outs_all.append(feature_outs.cpu())\n",
    "\n",
    "    feature_outs_all_final = torch.cat(feature_outs_all, dim=0).numpy()\n",
    "    #print(feature_outs_all_final.shape)\n",
    "\n",
    "    return feature_outs_all_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f39b57e-25a5-457b-86ff-ec488d85a09a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps = 1e-3\n",
    "def feature_engineer_for_index(x, feature_suffix):\n",
    "\n",
    "    aggs = [\n",
    "        (pl.col('word_count').max()/ pl.col(\"up_event\").filter(pl.col(\"up_event\") == '.').count()).clip(0, 500).alias('every_sentence_word_count'),\n",
    "        (pl.col('cursor_position').max()/ pl.col(\"word_count\").max()).alias('every_char_word'),\n",
    "        (pl.col('activations').filter(pl.col(\"activations\").is_in(['Remove/Cut', 'Replace'])).count()/ pl.col(\"up_event\").filter(pl.col(\"up_event\") == '.').count()).clip(0, 500).alias('every_sentence_change'),\n",
    "        ( pl.col(\"cursor_position\").max() / (pl.col('down_time').max() - pl.col('down_time').min()) * 1000 ).alias('char_per_min'),\n",
    "        ( pl.col(\"word_count\").max() / (pl.col('down_time').max() - pl.col('down_time').min()) * 1000 ).alias('word_per_min'),\n",
    "        \n",
    "        (pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"elapsed_time_diff_1\") > 8000 ).sum() / pl.col(\"elapsed_time_diff_1\").sum()).alias('proportion_of_pause_time'),\n",
    "        (pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"elapsed_time_diff_1\") > 8000 ).count()).alias('count_of_pause_time'),\n",
    "        (pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"elapsed_time_diff_1\") > 8000 ).sum() / pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"elapsed_time_diff_1\") > 10000 ).count()).alias('pause_length'),\n",
    "        (pl.col(\"elapsed_time_diff_1\").filter((pl.col(\"elapsed_time_diff_1\") > 8000) & (pl.col(\"text_change\") == ' ' )).count()).alias('freq_of_pause_time'),\n",
    "        #(pl.col(\"activations\").filter(pl.col(\"elapsed_time_diff_1\") > 2000 ).count() / pl.col(\"activations\").count()).alias('proportion_of_pause'),\n",
    "        # (pl.col('down_event').filter(pl.col('down_event').is_in(punctuations)).count() ).alias('punct_cnt'),\n",
    "        #*[(pl.col('text_change').filter(pl.col('text_change') == c).count() ).alias(f'text_change_{c}_cnt') for c in text_changes],\n",
    "        #pl.col('event_id').count().alias('event_count'),\n",
    "        *[pl.col(c).drop_nulls().n_unique().alias(f\"{c}_unique_{feature_suffix}\") for c in CATS],\n",
    "        *[pl.col(c).quantile(0.1, \"nearest\").alias(f\"{c}_quantile1_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.2, \"nearest\").alias(f\"{c}_quantile2_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.3, \"nearest\").alias(f\"{c}_quantile3_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.4, \"nearest\").alias(f\"{c}_quantile4_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.5, \"nearest\").alias(f\"{c}_quantile5_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.6, \"nearest\").alias(f\"{c}_quantile6_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.7, \"nearest\").alias(f\"{c}_quantile7_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.8, \"nearest\").alias(f\"{c}_quantile8_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.9, \"nearest\").alias(f\"{c}_quantile9_{feature_suffix}\") for c in NUMS],\n",
    "\n",
    "        *[pl.col(c).mean().alias(f\"{c}_mean_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).std().alias(f\"{c}_std_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).min().alias(f\"{c}_min_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).max().alias(f\"{c}_max_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).median().alias(f\"{c}_median_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).sum().alias(f\"{c}_sum_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).skew().alias(f\"{c}_skew_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).kurtosis().alias(f\"{c}_kurtosis_{feature_suffix}\") for c in NUMS],\n",
    "        # adding rank features\n",
    "        *[pl.col(c).last().alias(f\"{c}_rank_{feature_suffix}\") for c in NUMS],\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).quantile(0.1, \"nearest\").alias(f\"{c}_ET_quantile1_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).quantile(0.2, \"nearest\").alias(f\"{c}_ET_quantile2_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).quantile(0.3, \"nearest\").alias(f\"{c}_ET_quantile3_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).quantile(0.4, \"nearest\").alias(f\"{c}_ET_quantile4_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).quantile(0.5, \"nearest\").alias(f\"{c}_ET_quantile5_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).quantile(0.6, \"nearest\").alias(f\"{c}_ET_quantile6_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).quantile(0.7, \"nearest\").alias(f\"{c}_ET_quantile7_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).quantile(0.8, \"nearest\").alias(f\"{c}_ET_quantile8_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).quantile(0.9, \"nearest\").alias(f\"{c}_ET_quantile9_{feature_suffix}\") for c in name_feature],\n",
    "        \n",
    "        *[pl.col(\"activations\").filter(pl.col(\"activations\") == c).count().alias(f\"{c}_name_counts{feature_suffix}\")for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).median().alias(f\"{c}_ET_median_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"activations\")==c).last().alias(f\"{c}_ET_rank_{feature_suffix}\") for c in name_feature],\n",
    "        #*[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"name\")==c).mode().alias(f\"{c}_ET_mode_{feature_suffix}\") for c in name_feature],\n",
    "        \n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).quantile(0.1, \"nearest\").alias(f\"{c}_ETD_quantile1_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).quantile(0.2, \"nearest\").alias(f\"{c}_ETD_quantile2_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).quantile(0.3, \"nearest\").alias(f\"{c}_ETD_quantile3_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).quantile(0.4, \"nearest\").alias(f\"{c}_ETD_quantile4_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).quantile(0.5, \"nearest\").alias(f\"{c}_ETD_quantile5_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).quantile(0.6, \"nearest\").alias(f\"{c}_ETD_quantile6_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).quantile(0.7, \"nearest\").alias(f\"{c}_ETD_quantile7_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).quantile(0.8, \"nearest\").alias(f\"{c}_ETD_quantile8_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).quantile(0.9, \"nearest\").alias(f\"{c}_ETD_quantile9_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).mean().alias(f\"{c}_ETD_mean_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).max().alias(f\"{c}_ETD_max_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).min().alias(f\"{c}_ETD_min_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).std().alias(f\"{c}_ETD_std_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).median().alias(f\"{c}_ETD_median_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"activations\")==c).last().alias(f\"{c}_ETD_rank_{feature_suffix}\") for c in name_feature],\n",
    "        \n",
    "        \n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).quantile(0.1, \"nearest\").alias(f\"{c}_CP_quantile1_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).quantile(0.2, \"nearest\").alias(f\"{c}_CP_quantile2_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).quantile(0.3, \"nearest\").alias(f\"{c}_CP_quantile3_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).quantile(0.4, \"nearest\").alias(f\"{c}_CP_quantile4_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).quantile(0.5, \"nearest\").alias(f\"{c}_CP_quantile5_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).quantile(0.6, \"nearest\").alias(f\"{c}_CP_quantile6_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).quantile(0.7, \"nearest\").alias(f\"{c}_CP_quantile7_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).quantile(0.8, \"nearest\").alias(f\"{c}_CP_quantile8_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).quantile(0.9, \"nearest\").alias(f\"{c}_CP_quantile9_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).mean().alias(f\"{c}_CP_mean_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).max().alias(f\"{c}_CP_max_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).min().alias(f\"{c}_CP_min_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).std().alias(f\"{c}_CP_std_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).median().alias(f\"{c}_CP_median_{feature_suffix}\") for c in name_feature],\n",
    "        *[pl.col(\"cursor_position_diff\").filter(pl.col(\"activations\")==c).last().alias(f\"{c}_CP_rank_{feature_suffix}\") for c in name_feature],\n",
    "        \n",
    "        \n",
    "        *[pl.col(\"activations\").filter(pl.col(\"down_event\") == c).count().alias(f\"{c}_event_name_counts{feature_suffix}\")for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).quantile(0.1, \"nearest\").alias(f\"DE_{c}_ET_quantile1_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).quantile(0.2, \"nearest\").alias(f\"DE_{c}_ET_quantile2_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).quantile(0.3, \"nearest\").alias(f\"DE_{c}_ET_quantile3_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).quantile(0.4, \"nearest\").alias(f\"DE_{c}_ET_quantile4_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).quantile(0.5, \"nearest\").alias(f\"DE_{c}_ET_quantile5_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).quantile(0.6, \"nearest\").alias(f\"DE_{c}_ET_quantile6_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).quantile(0.7, \"nearest\").alias(f\"DE_{c}_ET_quantile7_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).quantile(0.8, \"nearest\").alias(f\"DE_{c}_ET_quantile8_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).quantile(0.9, \"nearest\").alias(f\"DE_{c}_ET_quantile9_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).mean().alias(f\"DE_{c}_ET_mean_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).std().alias(f\"DE_{c}_ET_std_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).max().alias(f\"DE_{c}_ET_max_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).min().alias(f\"DE_{c}_ET_min_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).median().alias(f\"DE_{c}_ET_median_{feature_suffix}\") for c in down_event_feature],\n",
    "        # adding rank features\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"down_event\")==c).last().alias(f\"DE_{c}_ET_rank_{feature_suffix}\") for c in down_event_feature],\n",
    "        \n",
    "        \n",
    "        \n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).quantile(0.1, \"nearest\").alias(f\"DE_{c}_ETD_quantile1_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).quantile(0.2, \"nearest\").alias(f\"DE_{c}_ETD_quantile2_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).quantile(0.3, \"nearest\").alias(f\"DE_{c}_ETD_quantile3_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).quantile(0.4, \"nearest\").alias(f\"DE_{c}_ETD_quantile4_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).quantile(0.5, \"nearest\").alias(f\"DE_{c}_ETD_quantile5_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).quantile(0.6, \"nearest\").alias(f\"DE_{c}_ETD_quantile6_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).quantile(0.7, \"nearest\").alias(f\"DE_{c}_ETD_quantile7_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).quantile(0.8, \"nearest\").alias(f\"DE_{c}_ETD_quantile8_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).quantile(0.9, \"nearest\").alias(f\"DE_{c}_ETD_quantile9_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).mean().alias(f\"DE_{c}_ETD_mean_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).max().alias(f\"DE_{c}_ETD_max_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).min().alias(f\"DE_{c}_ETD_min_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).std().alias(f\"DE_{c}_ETD_std_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).median().alias(f\"DE_{c}_ETD_median_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"elapsed_time_diff_1\").filter(pl.col(\"down_event\")==c).last().alias(f\"DE_{c}_ETD_rank_{feature_suffix}\") for c in down_event_feature],\n",
    "        \n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).quantile(0.1, \"nearest\").alias(f\"DE_{c}_DT_quantile1_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).quantile(0.2, \"nearest\").alias(f\"DE_{c}_DT_quantile2_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).quantile(0.3, \"nearest\").alias(f\"DE_{c}_DT_quantile3_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).quantile(0.4, \"nearest\").alias(f\"DE_{c}_DT_quantile4_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).quantile(0.5, \"nearest\").alias(f\"DE_{c}_DT_quantile5_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).quantile(0.6, \"nearest\").alias(f\"DE_{c}_DT_quantile6_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).quantile(0.7, \"nearest\").alias(f\"DE_{c}_DT_quantile7_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).quantile(0.8, \"nearest\").alias(f\"DE_{c}_DT_quantile8_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).quantile(0.9, \"nearest\").alias(f\"DE_{c}_DT_quantile9_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).mean().alias(f\"DE_{c}_DT_mean_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).max().alias(f\"DE_{c}_DT_max_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).min().alias(f\"DE_{c}_DT_min_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).std().alias(f\"DE_{c}_DT_std_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).median().alias(f\"DE_{c}_DT_median_{feature_suffix}\") for c in down_event_feature],\n",
    "        *[pl.col(\"down_time\").filter(pl.col(\"down_event\")==c).last().alias(f\"DE_{c}_DT_rank_{feature_suffix}\") for c in down_event_feature],\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        *[pl.col(\"activations\").filter(pl.col(\"up_event\") == c).count().alias(f\"UE_{c}_event_name_counts{feature_suffix}\")for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).quantile(0.1, \"nearest\").alias(f\"UE_{c}_ET_quantile1_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).quantile(0.2, \"nearest\").alias(f\"UE_{c}_ET_quantile2_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).quantile(0.3, \"nearest\").alias(f\"UE_{c}_ET_quantile3_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).quantile(0.4, \"nearest\").alias(f\"UE_{c}_ET_quantile4_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).quantile(0.5, \"nearest\").alias(f\"UE_{c}_ET_quantile5_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).quantile(0.6, \"nearest\").alias(f\"UE_{c}_ET_quantile6_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).quantile(0.7, \"nearest\").alias(f\"UE_{c}_ET_quantile7_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).quantile(0.8, \"nearest\").alias(f\"UE_{c}_ET_quantile8_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).quantile(0.9, \"nearest\").alias(f\"UE_{c}_ET_quantile9_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).mean().alias(f\"UE_{c}_ET_mean_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).std().alias(f\"UE_{c}_ET_std_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).max().alias(f\"UE_{c}_ET_max_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).min().alias(f\"UE_{c}_ET_min_{feature_suffix}\") for c in up_event_feature],\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).median().alias(f\"UE_{c}_ET_median_{feature_suffix}\") for c in up_event_feature],\n",
    "        # adding rank features\n",
    "        *[pl.col(\"action_time\").filter(pl.col(\"up_event\")==c).last().alias(f\"UE_{c}_ET_rank_{feature_suffix}\") for c in up_event_feature],\n",
    "\n",
    "\n",
    "        ]\n",
    "\n",
    "    df = x.groupby([\"id\"], maintain_order=True).agg(aggs).sort(\"id\")\n",
    "    tmp_df = x.filter((~x['text_change'].str.contains('=>'))&(x['text_change'] != 'NoChange'))\n",
    "    tmp_df = tmp_df.groupby('id').agg(pl.col(\"text_change\"))\n",
    "    tmp_df = tmp_df.with_columns([pl.col(\"text_change\").apply(lambda x: ''.join(x)).alias(\"text_change\")])\n",
    "    corpus = text_df['text'].tolist()\n",
    "    tmp_df = tmp_df.with_columns([pl.col(\"text_change\").apply(lambda x: re.findall(r'q+', x)).alias(\"text_change\")])\n",
    "    tmp_df = tmp_df.with_columns([pl.col(\"text_change\").apply(lambda x: len(x)).alias(\"input_word_count\")])\n",
    "    tmp_df = tmp_df.with_columns([pl.col(\"text_change\").apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0) ).alias(\"input_word_length_mean\")])\n",
    "    tmp_df = tmp_df.with_columns([pl.col(\"text_change\").apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0) ).alias(\"input_word_length_max\")])\n",
    "    tmp_df = tmp_df.with_columns([pl.col(\"text_change\").apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0) ).alias(\"input_word_length_std\")])\n",
    "    tmp_df = tmp_df.drop([\"text_change\"])\n",
    "    df = df.join(tmp_df, on='id')\n",
    "    df = df.to_pandas()\n",
    "    df['word_time_ratio'] = df[f\"word_count_max_{feature_suffix}\"] / df[f\"down_time_max_{feature_suffix}\"]\n",
    "    #df['word_event_ratio'] = df[f\"word_count_max_{feature_suffix}\"] / df['event_count']\n",
    "    #df['event_time_ratio'] = df['event_count']  / df[f\"down_time_max_{feature_suffix}\"]\n",
    "    df['idle_time_ratio'] = df[f\"elapsed_time_diff_1_sum_{feature_suffix}\"] / df[f\"down_time_max_{feature_suffix}\"]\n",
    "    \n",
    "    text_feature = pipe.transform(corpus).toarray() # pipe.transform(corpus).toarray() # get_model_feature(model, texts)\n",
    "    text_feature_df = pd.DataFrame(text_feature, columns=[f'text_features_{i}' for i in range(text_feature.shape[1])])\n",
    "    text_feature_df['id'] = text_df['id']\n",
    "    text_feature_df = text_feature_df.set_index('id')\n",
    "\n",
    "    df = df.join(text_feature_df, on='id')\n",
    "    #df = df.join(bert_result, on='id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b700978-a98e-45fc-995a-b35886334eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = feature_engineer_for_index(df, 'index_')\n",
    "invalid_columns = [c for c in df.columns if '[' in c or ']' in c or '<' in c]\n",
    "rename_dict = {}\n",
    "for name in invalid_columns:\n",
    "    rename_dict[name] = name.replace('[', 'left_brackets').replace(']', 'right_brackets').replace('<', 'less')\n",
    "df = df.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0d8d4d2-e072-4dd0-90f9-a576880275bd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "word_count_diff_1_quantile1_index_\n",
      "word_count_diff_1_quantile2_index_\n",
      "word_count_diff_2_quantile2_index_\n",
      "word_count_diff_3_quantile2_index_\n",
      "word_count_diff_1_quantile3_index_\n",
      "word_count_diff_2_quantile3_index_\n",
      "word_count_diff_3_quantile3_index_\n",
      "word_count_diff_1_quantile4_index_\n",
      "word_count_diff_2_quantile4_index_\n",
      "word_count_diff_3_quantile4_index_\n",
      "word_count_diff_1_quantile5_index_\n",
      "word_count_diff_2_quantile5_index_\n",
      "word_count_diff_1_quantile6_index_\n",
      "word_count_diff_1_quantile7_index_\n",
      "cursor_position_min_index_\n",
      "word_count_diff_1_median_index_\n",
      "word_count_diff_2_median_index_\n",
      "Input_CP_quantile1_index_\n",
      "Input_CP_quantile2_index_\n",
      "Input_CP_quantile3_index_\n",
      "Input_CP_quantile4_index_\n",
      "Input_CP_quantile5_index_\n",
      "Input_CP_quantile6_index_\n",
      "Input_CP_quantile7_index_\n",
      "Input_CP_quantile8_index_\n",
      "Input_CP_quantile9_index_\n",
      "Input_CP_median_index_\n",
      "Input_CP_rank_index_\n",
      "DE_Shift_ET_quantile1_index_\n",
      "DE_Shift_ET_quantile2_index_\n",
      "DE_Shift_ET_quantile3_index_\n",
      "DE_Shift_ET_quantile4_index_\n",
      "DE_Shift_ET_quantile5_index_\n",
      "DE_Shift_ET_quantile6_index_\n",
      "DE_Shift_ET_quantile7_index_\n",
      "DE_Shift_ET_quantile8_index_\n",
      "DE_Shift_ET_quantile9_index_\n",
      "DE_Shift_ET_mean_index_\n",
      "DE_Shift_ET_std_index_\n",
      "DE_Shift_ET_max_index_\n",
      "DE_Shift_ET_min_index_\n",
      "DE_Shift_ET_median_index_\n",
      "DE_Shift_ET_rank_index_\n",
      "UE_Shift_ET_quantile1_index_\n",
      "UE_Shift_ET_quantile2_index_\n",
      "UE_Shift_ET_quantile3_index_\n",
      "UE_Shift_ET_quantile4_index_\n",
      "UE_Shift_ET_quantile5_index_\n",
      "UE_Shift_ET_quantile6_index_\n",
      "UE_Shift_ET_quantile7_index_\n",
      "UE_Shift_ET_quantile8_index_\n",
      "UE_Shift_ET_quantile9_index_\n",
      "UE_Shift_ET_mean_index_\n",
      "UE_Shift_ET_std_index_\n",
      "UE_Shift_ET_max_index_\n",
      "UE_Shift_ET_min_index_\n",
      "UE_Shift_ET_median_index_\n",
      "UE_Shift_ET_rank_index_\n",
      "*********df DONE*********\n"
     ]
    }
   ],
   "source": [
    "# some cleaning...\n",
    "null1 = df.isnull().sum().sort_values(ascending=False) / len(df)\n",
    "\n",
    "\n",
    "drop1 = list(null1[null1>0.9].index)\n",
    "\n",
    "print(len(drop1))\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].nunique()==1:\n",
    "        print(col)\n",
    "        drop1.append(col)\n",
    "print(\"*********df DONE*********\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d2c36b7-cfa9-4d73-9292-358e27e1918e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#drop1 += not_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "163b8fa0-0d91-4826-9d19-f4eae7606b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES = [c for c in df.columns if c not in drop1 + ['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2f09ab1-29cc-469d-8d25-83fca6ae85c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1620"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e7933f5-5c8c-4408-a631-c8c04bcfc275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>every_sentence_word_count</th>\n",
       "      <th>every_char_word</th>\n",
       "      <th>every_sentence_change</th>\n",
       "      <th>char_per_min</th>\n",
       "      <th>word_per_min</th>\n",
       "      <th>proportion_of_pause_time</th>\n",
       "      <th>count_of_pause_time</th>\n",
       "      <th>pause_length</th>\n",
       "      <th>freq_of_pause_time</th>\n",
       "      <th>activations_unique_index_</th>\n",
       "      <th>...</th>\n",
       "      <th>text_features_38</th>\n",
       "      <th>text_features_39</th>\n",
       "      <th>text_features_40</th>\n",
       "      <th>text_features_41</th>\n",
       "      <th>text_features_42</th>\n",
       "      <th>text_features_43</th>\n",
       "      <th>text_features_44</th>\n",
       "      <th>text_features_45</th>\n",
       "      <th>text_features_46</th>\n",
       "      <th>text_features_47</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fde20dd8</th>\n",
       "      <td>12.596491</td>\n",
       "      <td>5.126741</td>\n",
       "      <td>25.403509</td>\n",
       "      <td>2.085945</td>\n",
       "      <td>0.406875</td>\n",
       "      <td>0.168502</td>\n",
       "      <td>13</td>\n",
       "      <td>20855.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842d59a3</th>\n",
       "      <td>18.403226</td>\n",
       "      <td>5.192813</td>\n",
       "      <td>4.677419</td>\n",
       "      <td>3.232087</td>\n",
       "      <td>0.622415</td>\n",
       "      <td>0.221349</td>\n",
       "      <td>16</td>\n",
       "      <td>22094.888889</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d06feb60</th>\n",
       "      <td>22.222222</td>\n",
       "      <td>6.067500</td>\n",
       "      <td>31.388889</td>\n",
       "      <td>1.366254</td>\n",
       "      <td>0.225176</td>\n",
       "      <td>0.554864</td>\n",
       "      <td>34</td>\n",
       "      <td>29721.545455</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3b5cd2b2</th>\n",
       "      <td>21.500000</td>\n",
       "      <td>5.754611</td>\n",
       "      <td>25.672414</td>\n",
       "      <td>4.010514</td>\n",
       "      <td>0.696922</td>\n",
       "      <td>0.355067</td>\n",
       "      <td>11</td>\n",
       "      <td>38380.125000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1dc5440c</th>\n",
       "      <td>20.363636</td>\n",
       "      <td>6.183036</td>\n",
       "      <td>10.181818</td>\n",
       "      <td>0.815264</td>\n",
       "      <td>0.131855</td>\n",
       "      <td>0.408144</td>\n",
       "      <td>38</td>\n",
       "      <td>25269.962963</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9f3cc888</th>\n",
       "      <td>9.434783</td>\n",
       "      <td>6.230415</td>\n",
       "      <td>5.434783</td>\n",
       "      <td>0.881389</td>\n",
       "      <td>0.141466</td>\n",
       "      <td>0.431006</td>\n",
       "      <td>23</td>\n",
       "      <td>31197.789474</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfbc5b5e</th>\n",
       "      <td>18.069767</td>\n",
       "      <td>5.962677</td>\n",
       "      <td>31.976744</td>\n",
       "      <td>2.599682</td>\n",
       "      <td>0.435992</td>\n",
       "      <td>0.285243</td>\n",
       "      <td>16</td>\n",
       "      <td>31745.636364</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31ead610</th>\n",
       "      <td>19.187500</td>\n",
       "      <td>5.993485</td>\n",
       "      <td>15.437500</td>\n",
       "      <td>1.034373</td>\n",
       "      <td>0.172583</td>\n",
       "      <td>0.814255</td>\n",
       "      <td>19</td>\n",
       "      <td>67820.944444</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394c1342</th>\n",
       "      <td>13.863636</td>\n",
       "      <td>5.642623</td>\n",
       "      <td>42.681818</td>\n",
       "      <td>0.954745</td>\n",
       "      <td>0.169202</td>\n",
       "      <td>0.534655</td>\n",
       "      <td>31</td>\n",
       "      <td>31291.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a1281c8</th>\n",
       "      <td>14.457143</td>\n",
       "      <td>5.622530</td>\n",
       "      <td>19.142857</td>\n",
       "      <td>1.594013</td>\n",
       "      <td>0.283505</td>\n",
       "      <td>0.459025</td>\n",
       "      <td>21</td>\n",
       "      <td>39258.375000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2471 rows × 1620 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          every_sentence_word_count  every_char_word  every_sentence_change  \\\n",
       "id                                                                            \n",
       "fde20dd8                  12.596491         5.126741              25.403509   \n",
       "842d59a3                  18.403226         5.192813               4.677419   \n",
       "d06feb60                  22.222222         6.067500              31.388889   \n",
       "3b5cd2b2                  21.500000         5.754611              25.672414   \n",
       "1dc5440c                  20.363636         6.183036              10.181818   \n",
       "...                             ...              ...                    ...   \n",
       "9f3cc888                   9.434783         6.230415               5.434783   \n",
       "dfbc5b5e                  18.069767         5.962677              31.976744   \n",
       "31ead610                  19.187500         5.993485              15.437500   \n",
       "394c1342                  13.863636         5.642623              42.681818   \n",
       "3a1281c8                  14.457143         5.622530              19.142857   \n",
       "\n",
       "          char_per_min  word_per_min  proportion_of_pause_time  \\\n",
       "id                                                               \n",
       "fde20dd8      2.085945      0.406875                  0.168502   \n",
       "842d59a3      3.232087      0.622415                  0.221349   \n",
       "d06feb60      1.366254      0.225176                  0.554864   \n",
       "3b5cd2b2      4.010514      0.696922                  0.355067   \n",
       "1dc5440c      0.815264      0.131855                  0.408144   \n",
       "...                ...           ...                       ...   \n",
       "9f3cc888      0.881389      0.141466                  0.431006   \n",
       "dfbc5b5e      2.599682      0.435992                  0.285243   \n",
       "31ead610      1.034373      0.172583                  0.814255   \n",
       "394c1342      0.954745      0.169202                  0.534655   \n",
       "3a1281c8      1.594013      0.283505                  0.459025   \n",
       "\n",
       "          count_of_pause_time  pause_length  freq_of_pause_time  \\\n",
       "id                                                                \n",
       "fde20dd8                   13  20855.111111                   1   \n",
       "842d59a3                   16  22094.888889                   2   \n",
       "d06feb60                   34  29721.545455                   6   \n",
       "3b5cd2b2                   11  38380.125000                   2   \n",
       "1dc5440c                   38  25269.962963                   2   \n",
       "...                       ...           ...                 ...   \n",
       "9f3cc888                   23  31197.789474                   7   \n",
       "dfbc5b5e                   16  31745.636364                   4   \n",
       "31ead610                   19  67820.944444                   9   \n",
       "394c1342                   31  31291.000000                   3   \n",
       "3a1281c8                   21  39258.375000                   1   \n",
       "\n",
       "          activations_unique_index_  ...  text_features_38  text_features_39  \\\n",
       "id                                   ...                                       \n",
       "fde20dd8                          5  ...               0.0               0.0   \n",
       "842d59a3                          3  ...               0.0               0.0   \n",
       "d06feb60                          3  ...               0.0               0.0   \n",
       "3b5cd2b2                          3  ...               0.0               0.0   \n",
       "1dc5440c                          4  ...               0.0               0.0   \n",
       "...                             ...  ...               ...               ...   \n",
       "9f3cc888                          3  ...               0.0               0.0   \n",
       "dfbc5b5e                          3  ...               0.0               0.0   \n",
       "31ead610                          3  ...               0.0               0.0   \n",
       "394c1342                          4  ...               0.0               0.0   \n",
       "3a1281c8                          3  ...               0.0               0.0   \n",
       "\n",
       "          text_features_40  text_features_41  text_features_42  \\\n",
       "id                                                               \n",
       "fde20dd8               0.0               0.0               0.0   \n",
       "842d59a3               0.0               0.0               0.0   \n",
       "d06feb60               0.0               0.0               0.0   \n",
       "3b5cd2b2               0.0               0.0               0.0   \n",
       "1dc5440c               0.0               0.0               0.0   \n",
       "...                    ...               ...               ...   \n",
       "9f3cc888               0.0               0.0               0.0   \n",
       "dfbc5b5e               0.0               0.0               0.0   \n",
       "31ead610               0.0               0.0               0.0   \n",
       "394c1342               0.0               0.0               0.0   \n",
       "3a1281c8               0.0               0.0               0.0   \n",
       "\n",
       "          text_features_43  text_features_44  text_features_45  \\\n",
       "id                                                               \n",
       "fde20dd8               0.0               0.0               0.0   \n",
       "842d59a3               0.0               0.0               0.0   \n",
       "d06feb60               0.0               0.0               0.0   \n",
       "3b5cd2b2               0.0               0.0               0.0   \n",
       "1dc5440c               0.0               0.0               0.0   \n",
       "...                    ...               ...               ...   \n",
       "9f3cc888               0.0               0.0               0.0   \n",
       "dfbc5b5e               0.0               0.0               0.0   \n",
       "31ead610               0.0               0.0               0.0   \n",
       "394c1342               0.0               0.0               0.0   \n",
       "3a1281c8               0.0               0.0               0.0   \n",
       "\n",
       "          text_features_46  text_features_47  \n",
       "id                                            \n",
       "fde20dd8               0.0               0.0  \n",
       "842d59a3               0.0               0.0  \n",
       "d06feb60               0.0               0.0  \n",
       "3b5cd2b2               0.0               0.0  \n",
       "1dc5440c               0.0               0.0  \n",
       "...                    ...               ...  \n",
       "9f3cc888               0.0               0.0  \n",
       "dfbc5b5e               0.0               0.0  \n",
       "31ead610               0.0               0.0  \n",
       "394c1342               0.0               0.0  \n",
       "3a1281c8               0.0               0.0  \n",
       "\n",
       "[2471 rows x 1620 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.set_index('id')\n",
    "df = df[FEATURES]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc066084-44bf-4c94-ad35-dae858e75a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>every_sentence_word_count</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>17.818535</td>\n",
       "      <td>13.062090</td>\n",
       "      <td>2.197802</td>\n",
       "      <td>13.431677</td>\n",
       "      <td>16.409091</td>\n",
       "      <td>19.841667</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>every_char_word</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>5.764699</td>\n",
       "      <td>0.555682</td>\n",
       "      <td>3.544469</td>\n",
       "      <td>5.506235</td>\n",
       "      <td>5.739910</td>\n",
       "      <td>5.985366</td>\n",
       "      <td>14.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>every_sentence_change</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>17.737873</td>\n",
       "      <td>21.296764</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>8.343137</td>\n",
       "      <td>14.095238</td>\n",
       "      <td>22.153846</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_per_min</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>1.311744</td>\n",
       "      <td>0.581970</td>\n",
       "      <td>0.128895</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>1.171892</td>\n",
       "      <td>1.605255</td>\n",
       "      <td>4.974864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_per_min</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>0.229235</td>\n",
       "      <td>0.103489</td>\n",
       "      <td>0.021794</td>\n",
       "      <td>0.149384</td>\n",
       "      <td>0.206804</td>\n",
       "      <td>0.281960</td>\n",
       "      <td>0.885433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_features_43</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_features_44</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_features_45</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_features_46</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_features_47</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1620 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count       mean        std       min        25%  \\\n",
       "every_sentence_word_count  2471.0  17.818535  13.062090  2.197802  13.431677   \n",
       "every_char_word            2471.0   5.764699   0.555682  3.544469   5.506235   \n",
       "every_sentence_change      2471.0  17.737873  21.296764  0.181818   8.343137   \n",
       "char_per_min               2471.0   1.311744   0.581970  0.128895   0.877846   \n",
       "word_per_min               2471.0   0.229235   0.103489  0.021794   0.149384   \n",
       "...                           ...        ...        ...       ...        ...   \n",
       "text_features_43           2471.0   0.000028   0.001410  0.000000   0.000000   \n",
       "text_features_44           2471.0   0.000028   0.001392  0.000000   0.000000   \n",
       "text_features_45           2471.0   0.000050   0.002465  0.000000   0.000000   \n",
       "text_features_46           2471.0   0.000023   0.001121  0.000000   0.000000   \n",
       "text_features_47           2471.0   0.000023   0.001121  0.000000   0.000000   \n",
       "\n",
       "                                 50%        75%         max  \n",
       "every_sentence_word_count  16.409091  19.841667  500.000000  \n",
       "every_char_word             5.739910   5.985366   14.500000  \n",
       "every_sentence_change      14.095238  22.153846  500.000000  \n",
       "char_per_min                1.171892   1.605255    4.974864  \n",
       "word_per_min                0.206804   0.281960    0.885433  \n",
       "...                              ...        ...         ...  \n",
       "text_features_43            0.000000   0.000000    0.070085  \n",
       "text_features_44            0.000000   0.000000    0.069196  \n",
       "text_features_45            0.000000   0.000000    0.122540  \n",
       "text_features_46            0.000000   0.000000    0.055724  \n",
       "text_features_47            0.000000   0.000000    0.055724  \n",
       "\n",
       "[1620 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40ff6d59-ccec-434e-8266-1577ea1918b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv('train_scores.csv')\n",
    "target = target.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a22cb8b-c357-41e4-873b-9d86a23e468e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "oof_xgb = pd.DataFrame(data=np.zeros((len(target),3)), index=target.index, columns=['xgb', 'lgbm', 'cat'])\n",
    "#models = {}\n",
    "best_iteration_xgb = defaultdict(list)\n",
    "importance_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric':'rmse',\n",
    "        'learning_rate': 0.02,\n",
    "        'alpha': 8,\n",
    "        'max_depth': 4,\n",
    "        'subsample':0.8,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'seed': 42\n",
    "        }\n",
    "\n",
    "xgb_params['n_estimators'] = 500\n",
    "\n",
    "\n",
    "lgbm_params = {\n",
    "    'objective' : 'regression',\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 4,\n",
    "    'num_iterations': 500,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    \n",
    "    'learning_rate': 0.02,\n",
    "    'depth': 8,\n",
    "    'iterations': 500,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "df = df.join(target)\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c88d2206-08e9-4836-9800-6da321c42c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_target = {0.5: 0,\n",
    "                    1.0: 1,\n",
    "                    1.5: 2,\n",
    "                    2.0: 3,\n",
    "                    2.5: 4,\n",
    "                    3.0: 5,\n",
    "                    3.5: 6,\n",
    "                    4.0: 7,\n",
    "                    4.5: 8,\n",
    "                    5.0: 9,\n",
    "                    5.5: 10,\n",
    "                    6.0: 11,}\n",
    "\n",
    "reverse_convert_target = {0:0.5,\n",
    "                            1:1.0,\n",
    "                            2:1.5,\n",
    "                            3:2.0,\n",
    "                            4:2.5,\n",
    "                            5:3.0,\n",
    "                            6:3.5,\n",
    "                            7:4.0,\n",
    "                            8:4.5,\n",
    "                            9:5.0,\n",
    "                            10:5.5,\n",
    "                            11:6.0,}\n",
    "df['new_label'] = df['score'].map(convert_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "127f968c-e6c0-434d-883e-68331a57344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ae_mlp(num_columns, hidden_units=[256,512,1024,1024,512,256], lr = 1e-3):\n",
    "    \n",
    "    inp = tf.keras.layers.Input(shape = (num_columns, ))\n",
    "    out = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(512, activation=\"tanh\",),\n",
    "        #keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(512, activation=\"tanh\"),\n",
    "        #keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(256, activation=\"tanh\"),\n",
    "        #keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(1,),\n",
    "    ]\n",
    "    )(inp)\n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = [out])\n",
    "    model.compile(optimizer = tf.keras.optimizers.AdamW(learning_rate = lr),\n",
    "                  loss = \"MSE\",\n",
    "                  metrics =[tf.keras.metrics.RootMeanSquaredError()]\n",
    "                            , \n",
    "                 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a0bb0b9-6af0-4983-908d-0b809fa165ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0).clip(-1e9, 1e9)\n",
    "\n",
    "train_mean = df[FEATURES].mean()\n",
    "train_std = df[FEATURES].std()\n",
    "\n",
    "train_min = df[FEATURES].min()\n",
    "train_max = df[FEATURES].max()\n",
    "\n",
    "df[FEATURES] = (df[FEATURES] - train_min) /  (train_max - train_min)\n",
    "df = df.fillna(0).clip(-1e9, 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15f53d9b-8fab-4475-81dc-2f22ef3d08bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>every_sentence_word_count</th>\n",
       "      <th>every_char_word</th>\n",
       "      <th>every_sentence_change</th>\n",
       "      <th>char_per_min</th>\n",
       "      <th>word_per_min</th>\n",
       "      <th>proportion_of_pause_time</th>\n",
       "      <th>count_of_pause_time</th>\n",
       "      <th>pause_length</th>\n",
       "      <th>freq_of_pause_time</th>\n",
       "      <th>activations_unique_index_</th>\n",
       "      <th>...</th>\n",
       "      <th>text_features_40</th>\n",
       "      <th>text_features_41</th>\n",
       "      <th>text_features_42</th>\n",
       "      <th>text_features_43</th>\n",
       "      <th>text_features_44</th>\n",
       "      <th>text_features_45</th>\n",
       "      <th>text_features_46</th>\n",
       "      <th>text_features_47</th>\n",
       "      <th>score</th>\n",
       "      <th>new_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791be024</th>\n",
       "      <td>0.016728</td>\n",
       "      <td>0.126137</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>0.227704</td>\n",
       "      <td>0.264414</td>\n",
       "      <td>0.464379</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955ea377</th>\n",
       "      <td>0.024354</td>\n",
       "      <td>0.223226</td>\n",
       "      <td>0.054728</td>\n",
       "      <td>0.257321</td>\n",
       "      <td>0.240724</td>\n",
       "      <td>0.452721</td>\n",
       "      <td>0.190909</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9d8ba1be</th>\n",
       "      <td>0.025230</td>\n",
       "      <td>0.217764</td>\n",
       "      <td>0.040439</td>\n",
       "      <td>0.305569</td>\n",
       "      <td>0.289060</td>\n",
       "      <td>0.425016</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8adb949f</th>\n",
       "      <td>0.029735</td>\n",
       "      <td>0.121707</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.101095</td>\n",
       "      <td>0.121654</td>\n",
       "      <td>0.503640</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1fbf2800</th>\n",
       "      <td>0.024681</td>\n",
       "      <td>0.175143</td>\n",
       "      <td>0.025452</td>\n",
       "      <td>0.280205</td>\n",
       "      <td>0.289872</td>\n",
       "      <td>0.619117</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343a4d2</th>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.170912</td>\n",
       "      <td>0.027210</td>\n",
       "      <td>0.413461</td>\n",
       "      <td>0.430601</td>\n",
       "      <td>0.401843</td>\n",
       "      <td>0.190909</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5cdb9757</th>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.190778</td>\n",
       "      <td>0.044110</td>\n",
       "      <td>0.334360</td>\n",
       "      <td>0.334222</td>\n",
       "      <td>0.610403</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4080033</th>\n",
       "      <td>0.026341</td>\n",
       "      <td>0.068922</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>0.268529</td>\n",
       "      <td>0.499112</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f79335cf</th>\n",
       "      <td>0.031045</td>\n",
       "      <td>0.169729</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.235181</td>\n",
       "      <td>0.246580</td>\n",
       "      <td>0.264479</td>\n",
       "      <td>0.190909</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52125f9b</th>\n",
       "      <td>0.033050</td>\n",
       "      <td>0.228296</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>0.235032</td>\n",
       "      <td>0.217593</td>\n",
       "      <td>0.670878</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2471 rows × 1622 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          every_sentence_word_count  every_char_word  every_sentence_change  \\\n",
       "id                                                                            \n",
       "791be024                   0.016728         0.126137               0.021494   \n",
       "955ea377                   0.024354         0.223226               0.054728   \n",
       "9d8ba1be                   0.025230         0.217764               0.040439   \n",
       "8adb949f                   0.029735         0.121707               0.021644   \n",
       "1fbf2800                   0.024681         0.175143               0.025452   \n",
       "...                             ...              ...                    ...   \n",
       "1343a4d2                   0.021079         0.170912               0.027210   \n",
       "5cdb9757                   0.027152         0.190778               0.044110   \n",
       "f4080033                   0.026341         0.068922               0.012675   \n",
       "f79335cf                   0.031045         0.169729               0.014946   \n",
       "52125f9b                   0.033050         0.228296               0.016442   \n",
       "\n",
       "          char_per_min  word_per_min  proportion_of_pause_time  \\\n",
       "id                                                               \n",
       "791be024      0.227704      0.264414                  0.464379   \n",
       "955ea377      0.257321      0.240724                  0.452721   \n",
       "9d8ba1be      0.305569      0.289060                  0.425016   \n",
       "8adb949f      0.101095      0.121654                  0.503640   \n",
       "1fbf2800      0.280205      0.289872                  0.619117   \n",
       "...                ...           ...                       ...   \n",
       "1343a4d2      0.413461      0.430601                  0.401843   \n",
       "5cdb9757      0.334360      0.334222                  0.610403   \n",
       "f4080033      0.198500      0.268529                  0.499112   \n",
       "f79335cf      0.235181      0.246580                  0.264479   \n",
       "52125f9b      0.235032      0.217593                  0.670878   \n",
       "\n",
       "          count_of_pause_time  pause_length  freq_of_pause_time  \\\n",
       "id                                                                \n",
       "791be024             0.236364      0.000029            0.051282   \n",
       "955ea377             0.190909      0.000032            0.128205   \n",
       "9d8ba1be             0.300000      0.000025            0.153846   \n",
       "8adb949f             0.290909      0.000031            0.051282   \n",
       "1fbf2800             0.127273      0.000067            0.025641   \n",
       "...                       ...           ...                 ...   \n",
       "1343a4d2             0.190909      0.000023            0.025641   \n",
       "5cdb9757             0.181818      0.000041            0.025641   \n",
       "f4080033             0.109091      0.000074            0.025641   \n",
       "f79335cf             0.190909      0.000023            0.102564   \n",
       "52125f9b             0.318182      0.000036            0.000000   \n",
       "\n",
       "          activations_unique_index_  ...  text_features_40  text_features_41  \\\n",
       "id                                   ...                                       \n",
       "791be024                   0.000000  ...               0.0               0.0   \n",
       "955ea377                   0.333333  ...               0.0               0.0   \n",
       "9d8ba1be                   0.000000  ...               0.0               0.0   \n",
       "8adb949f                   0.333333  ...               0.0               0.0   \n",
       "1fbf2800                   0.333333  ...               0.0               0.0   \n",
       "...                             ...  ...               ...               ...   \n",
       "1343a4d2                   0.000000  ...               0.0               0.0   \n",
       "5cdb9757                   0.333333  ...               0.0               0.0   \n",
       "f4080033                   0.000000  ...               0.0               0.0   \n",
       "f79335cf                   0.666667  ...               0.0               0.0   \n",
       "52125f9b                   0.000000  ...               0.0               0.0   \n",
       "\n",
       "          text_features_42  text_features_43  text_features_44  \\\n",
       "id                                                               \n",
       "791be024               0.0               0.0               0.0   \n",
       "955ea377               0.0               0.0               0.0   \n",
       "9d8ba1be               0.0               0.0               0.0   \n",
       "8adb949f               0.0               0.0               0.0   \n",
       "1fbf2800               0.0               0.0               0.0   \n",
       "...                    ...               ...               ...   \n",
       "1343a4d2               0.0               0.0               0.0   \n",
       "5cdb9757               0.0               0.0               0.0   \n",
       "f4080033               0.0               0.0               0.0   \n",
       "f79335cf               0.0               0.0               0.0   \n",
       "52125f9b               0.0               0.0               0.0   \n",
       "\n",
       "          text_features_45  text_features_46  text_features_47  score  \\\n",
       "id                                                                      \n",
       "791be024               0.0               0.0               0.0    4.0   \n",
       "955ea377               0.0               0.0               0.0    4.5   \n",
       "9d8ba1be               0.0               0.0               0.0    5.0   \n",
       "8adb949f               0.0               0.0               0.0    2.5   \n",
       "1fbf2800               0.0               0.0               0.0    4.5   \n",
       "...                    ...               ...               ...    ...   \n",
       "1343a4d2               0.0               0.0               0.0    6.0   \n",
       "5cdb9757               0.0               0.0               0.0    4.5   \n",
       "f4080033               0.0               0.0               0.0    4.5   \n",
       "f79335cf               0.0               0.0               0.0    4.0   \n",
       "52125f9b               0.0               0.0               0.0    4.5   \n",
       "\n",
       "          new_label  \n",
       "id                   \n",
       "791be024          7  \n",
       "955ea377          8  \n",
       "9d8ba1be          9  \n",
       "8adb949f          4  \n",
       "1fbf2800          8  \n",
       "...             ...  \n",
       "1343a4d2         11  \n",
       "5cdb9757          8  \n",
       "f4080033          8  \n",
       "f79335cf          7  \n",
       "52125f9b          8  \n",
       "\n",
       "[2471 rows x 1622 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f5c7125-0f30-44cd-87c1-395ac96df248",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 , Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 17:12:57.153875: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-10-26 17:12:57.153911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: will-Super-Server\n",
      "2023-10-26 17:12:57.153918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: will-Super-Server\n",
      "2023-10-26 17:12:57.154023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 525.125.6\n",
      "2023-10-26 17:12:57.154040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.125.6\n",
      "2023-10-26 17:12:57.154045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 525.125.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/31 [==========================>...] - ETA: 0s - loss: 3.3659 - root_mean_squared_error: 1.8347\n",
      "Epoch 1: val_loss improved from inf to 1.06850, saving model to ./mlp/best_weights_0.hdf5\n",
      "31/31 [==============================] - 1s 13ms/step - loss: 3.1446 - root_mean_squared_error: 1.7733 - val_loss: 1.0685 - val_root_mean_squared_error: 1.0337\n",
      "Epoch 2/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.9049 - root_mean_squared_error: 0.9513\n",
      "Epoch 2: val_loss improved from 1.06850 to 0.62002, saving model to ./mlp/best_weights_0.hdf5\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 0.8833 - root_mean_squared_error: 0.9398 - val_loss: 0.6200 - val_root_mean_squared_error: 0.7874\n",
      "Epoch 3/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5538 - root_mean_squared_error: 0.7442\n",
      "Epoch 3: val_loss improved from 0.62002 to 0.49486, saving model to ./mlp/best_weights_0.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5507 - root_mean_squared_error: 0.7421 - val_loss: 0.4949 - val_root_mean_squared_error: 0.7035\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4723 - root_mean_squared_error: 0.6873\n",
      "Epoch 4: val_loss did not improve from 0.49486\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4723 - root_mean_squared_error: 0.6873 - val_loss: 0.5064 - val_root_mean_squared_error: 0.7117\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4480 - root_mean_squared_error: 0.6693\n",
      "Epoch 5: val_loss improved from 0.49486 to 0.47273, saving model to ./mlp/best_weights_0.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4480 - root_mean_squared_error: 0.6693 - val_loss: 0.4727 - val_root_mean_squared_error: 0.6876\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4329 - root_mean_squared_error: 0.6580\n",
      "Epoch 6: val_loss did not improve from 0.47273\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4329 - root_mean_squared_error: 0.6580 - val_loss: 0.4994 - val_root_mean_squared_error: 0.7067\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4671 - root_mean_squared_error: 0.6834\n",
      "Epoch 7: val_loss did not improve from 0.47273\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4671 - root_mean_squared_error: 0.6834 - val_loss: 0.5346 - val_root_mean_squared_error: 0.7312\n",
      "Epoch 8/50\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.4710 - root_mean_squared_error: 0.6863\n",
      "Epoch 8: val_loss did not improve from 0.47273\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4735 - root_mean_squared_error: 0.6881 - val_loss: 0.4859 - val_root_mean_squared_error: 0.6970\n",
      "Epoch 9/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.4287 - root_mean_squared_error: 0.6548\n",
      "Epoch 9: val_loss improved from 0.47273 to 0.45770, saving model to ./mlp/best_weights_0.hdf5\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.4276 - root_mean_squared_error: 0.6539 - val_loss: 0.4577 - val_root_mean_squared_error: 0.6765\n",
      "Epoch 10/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.4213 - root_mean_squared_error: 0.6490\n",
      "Epoch 10: val_loss improved from 0.45770 to 0.44355, saving model to ./mlp/best_weights_0.hdf5\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.4218 - root_mean_squared_error: 0.6495 - val_loss: 0.4436 - val_root_mean_squared_error: 0.6660\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4328 - root_mean_squared_error: 0.6579\n",
      "Epoch 11: val_loss improved from 0.44355 to 0.43457, saving model to ./mlp/best_weights_0.hdf5\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.4328 - root_mean_squared_error: 0.6579 - val_loss: 0.4346 - val_root_mean_squared_error: 0.6592\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3811 - root_mean_squared_error: 0.6173\n",
      "Epoch 12: val_loss did not improve from 0.43457\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3811 - root_mean_squared_error: 0.6173 - val_loss: 0.4349 - val_root_mean_squared_error: 0.6595\n",
      "Epoch 13/50\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.3962 - root_mean_squared_error: 0.6295\n",
      "Epoch 13: val_loss did not improve from 0.43457\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.3852 - root_mean_squared_error: 0.6207 - val_loss: 0.5149 - val_root_mean_squared_error: 0.7175\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4306 - root_mean_squared_error: 0.6562\n",
      "Epoch 14: val_loss did not improve from 0.43457\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4306 - root_mean_squared_error: 0.6562 - val_loss: 0.4445 - val_root_mean_squared_error: 0.6667\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4108 - root_mean_squared_error: 0.6409\n",
      "Epoch 15: val_loss did not improve from 0.43457\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4108 - root_mean_squared_error: 0.6409 - val_loss: 0.4658 - val_root_mean_squared_error: 0.6825\n",
      "Epoch 16/50\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.3917 - root_mean_squared_error: 0.6259\n",
      "Epoch 16: val_loss improved from 0.43457 to 0.42827, saving model to ./mlp/best_weights_0.hdf5\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.3844 - root_mean_squared_error: 0.6200 - val_loss: 0.4283 - val_root_mean_squared_error: 0.6544\n",
      "Epoch 17/50\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.3851 - root_mean_squared_error: 0.6205\n",
      "Epoch 17: val_loss improved from 0.42827 to 0.42754, saving model to ./mlp/best_weights_0.hdf5\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.3789 - root_mean_squared_error: 0.6155 - val_loss: 0.4275 - val_root_mean_squared_error: 0.6539\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3740 - root_mean_squared_error: 0.6116\n",
      "Epoch 18: val_loss did not improve from 0.42754\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3740 - root_mean_squared_error: 0.6116 - val_loss: 0.4329 - val_root_mean_squared_error: 0.6580\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3698 - root_mean_squared_error: 0.6081\n",
      "Epoch 19: val_loss did not improve from 0.42754\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3698 - root_mean_squared_error: 0.6081 - val_loss: 0.4292 - val_root_mean_squared_error: 0.6552\n",
      "Epoch 20/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.3492 - root_mean_squared_error: 0.5909\n",
      "Epoch 20: val_loss did not improve from 0.42754\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3584 - root_mean_squared_error: 0.5986 - val_loss: 0.5904 - val_root_mean_squared_error: 0.7684\n",
      "Epoch 21/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.4015 - root_mean_squared_error: 0.6337\n",
      "Epoch 21: val_loss did not improve from 0.42754\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.3951 - root_mean_squared_error: 0.6285 - val_loss: 0.5163 - val_root_mean_squared_error: 0.7186\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3688 - root_mean_squared_error: 0.6073\n",
      "Epoch 22: val_loss did not improve from 0.42754\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3688 - root_mean_squared_error: 0.6073 - val_loss: 0.4335 - val_root_mean_squared_error: 0.6584\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3485 - root_mean_squared_error: 0.5903\n",
      "Epoch 23: val_loss improved from 0.42754 to 0.42461, saving model to ./mlp/best_weights_0.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3485 - root_mean_squared_error: 0.5903 - val_loss: 0.4246 - val_root_mean_squared_error: 0.6516\n",
      "Epoch 24/50\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.3367 - root_mean_squared_error: 0.5802\n",
      "Epoch 24: val_loss did not improve from 0.42461\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.3399 - root_mean_squared_error: 0.5830 - val_loss: 0.4265 - val_root_mean_squared_error: 0.6531\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3577 - root_mean_squared_error: 0.5980\n",
      "Epoch 25: val_loss did not improve from 0.42461\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3577 - root_mean_squared_error: 0.5980 - val_loss: 0.5029 - val_root_mean_squared_error: 0.7092\n",
      "Epoch 26/50\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.3446 - root_mean_squared_error: 0.5870\n",
      "Epoch 26: val_loss did not improve from 0.42461\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.3404 - root_mean_squared_error: 0.5835 - val_loss: 0.4336 - val_root_mean_squared_error: 0.6585\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3583 - root_mean_squared_error: 0.5986\n",
      "Epoch 27: val_loss did not improve from 0.42461\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3583 - root_mean_squared_error: 0.5986 - val_loss: 0.4470 - val_root_mean_squared_error: 0.6686\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3314 - root_mean_squared_error: 0.5757\n",
      "Epoch 28: val_loss did not improve from 0.42461\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3314 - root_mean_squared_error: 0.5757 - val_loss: 0.4322 - val_root_mean_squared_error: 0.6574\n",
      "Epoch 29/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.3221 - root_mean_squared_error: 0.5675\n",
      "Epoch 29: val_loss did not improve from 0.42461\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.3264 - root_mean_squared_error: 0.5713 - val_loss: 0.4629 - val_root_mean_squared_error: 0.6804\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3327 - root_mean_squared_error: 0.5768\n",
      "Epoch 30: val_loss did not improve from 0.42461\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3327 - root_mean_squared_error: 0.5768 - val_loss: 0.4838 - val_root_mean_squared_error: 0.6955\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3925 - root_mean_squared_error: 0.6265\n",
      "Epoch 31: val_loss did not improve from 0.42461\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.3925 - root_mean_squared_error: 0.6265 - val_loss: 0.4344 - val_root_mean_squared_error: 0.6591\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3248 - root_mean_squared_error: 0.5699\n",
      "Epoch 32: val_loss did not improve from 0.42461\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3248 - root_mean_squared_error: 0.5699 - val_loss: 0.4386 - val_root_mean_squared_error: 0.6622\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3811 - root_mean_squared_error: 0.6173\n",
      "Epoch 33: val_loss did not improve from 0.42461\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3811 - root_mean_squared_error: 0.6173 - val_loss: 0.4992 - val_root_mean_squared_error: 0.7065\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "2 , Epoch 1/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 3.3401 - root_mean_squared_error: 1.8276\n",
      "Epoch 1: val_loss improved from inf to 1.00892, saving model to ./mlp/best_weights_1.hdf5\n",
      "31/31 [==============================] - 1s 14ms/step - loss: 3.2782 - root_mean_squared_error: 1.8106 - val_loss: 1.0089 - val_root_mean_squared_error: 1.0045\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.9659 - root_mean_squared_error: 0.9828\n",
      "Epoch 2: val_loss improved from 1.00892 to 0.79459, saving model to ./mlp/best_weights_1.hdf5\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.9659 - root_mean_squared_error: 0.9828 - val_loss: 0.7946 - val_root_mean_squared_error: 0.8914\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6307 - root_mean_squared_error: 0.7941\n",
      "Epoch 3: val_loss improved from 0.79459 to 0.76042, saving model to ./mlp/best_weights_1.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6307 - root_mean_squared_error: 0.7941 - val_loss: 0.7604 - val_root_mean_squared_error: 0.8720\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5472 - root_mean_squared_error: 0.7397\n",
      "Epoch 4: val_loss improved from 0.76042 to 0.48797, saving model to ./mlp/best_weights_1.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5472 - root_mean_squared_error: 0.7397 - val_loss: 0.4880 - val_root_mean_squared_error: 0.6985\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4704 - root_mean_squared_error: 0.6858\n",
      "Epoch 5: val_loss improved from 0.48797 to 0.45792, saving model to ./mlp/best_weights_1.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4704 - root_mean_squared_error: 0.6858 - val_loss: 0.4579 - val_root_mean_squared_error: 0.6767\n",
      "Epoch 6/50\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.4291 - root_mean_squared_error: 0.6550\n",
      "Epoch 6: val_loss improved from 0.45792 to 0.44917, saving model to ./mlp/best_weights_1.hdf5\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.4295 - root_mean_squared_error: 0.6554 - val_loss: 0.4492 - val_root_mean_squared_error: 0.6702\n",
      "Epoch 7/50\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.4875 - root_mean_squared_error: 0.6982\n",
      "Epoch 7: val_loss did not improve from 0.44917\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4861 - root_mean_squared_error: 0.6972 - val_loss: 0.4800 - val_root_mean_squared_error: 0.6928\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4233 - root_mean_squared_error: 0.6506\n",
      "Epoch 8: val_loss did not improve from 0.44917\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4233 - root_mean_squared_error: 0.6506 - val_loss: 0.4936 - val_root_mean_squared_error: 0.7026\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4212 - root_mean_squared_error: 0.6490\n",
      "Epoch 9: val_loss did not improve from 0.44917\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4212 - root_mean_squared_error: 0.6490 - val_loss: 0.5171 - val_root_mean_squared_error: 0.7191\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3965 - root_mean_squared_error: 0.6296\n",
      "Epoch 10: val_loss improved from 0.44917 to 0.42236, saving model to ./mlp/best_weights_1.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3965 - root_mean_squared_error: 0.6296 - val_loss: 0.4224 - val_root_mean_squared_error: 0.6499\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4020 - root_mean_squared_error: 0.6340\n",
      "Epoch 11: val_loss did not improve from 0.42236\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4020 - root_mean_squared_error: 0.6340 - val_loss: 0.4706 - val_root_mean_squared_error: 0.6860\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3859 - root_mean_squared_error: 0.6212\n",
      "Epoch 12: val_loss did not improve from 0.42236\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3859 - root_mean_squared_error: 0.6212 - val_loss: 0.5748 - val_root_mean_squared_error: 0.7582\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4145 - root_mean_squared_error: 0.6439\n",
      "Epoch 13: val_loss did not improve from 0.42236\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4145 - root_mean_squared_error: 0.6439 - val_loss: 0.5144 - val_root_mean_squared_error: 0.7172\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4104 - root_mean_squared_error: 0.6406\n",
      "Epoch 14: val_loss did not improve from 0.42236\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4104 - root_mean_squared_error: 0.6406 - val_loss: 0.4662 - val_root_mean_squared_error: 0.6828\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3903 - root_mean_squared_error: 0.6247\n",
      "Epoch 15: val_loss did not improve from 0.42236\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3903 - root_mean_squared_error: 0.6247 - val_loss: 0.4376 - val_root_mean_squared_error: 0.6615\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3882 - root_mean_squared_error: 0.6231\n",
      "Epoch 16: val_loss did not improve from 0.42236\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3882 - root_mean_squared_error: 0.6231 - val_loss: 0.4327 - val_root_mean_squared_error: 0.6578\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3659 - root_mean_squared_error: 0.6049\n",
      "Epoch 17: val_loss did not improve from 0.42236\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3659 - root_mean_squared_error: 0.6049 - val_loss: 0.4420 - val_root_mean_squared_error: 0.6648\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3523 - root_mean_squared_error: 0.5935\n",
      "Epoch 18: val_loss did not improve from 0.42236\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3523 - root_mean_squared_error: 0.5935 - val_loss: 0.4328 - val_root_mean_squared_error: 0.6579\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3450 - root_mean_squared_error: 0.5874\n",
      "Epoch 19: val_loss did not improve from 0.42236\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3450 - root_mean_squared_error: 0.5874 - val_loss: 0.4354 - val_root_mean_squared_error: 0.6598\n",
      "Epoch 20/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.3476 - root_mean_squared_error: 0.5896\n",
      "Epoch 20: val_loss did not improve from 0.42236\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3494 - root_mean_squared_error: 0.5911 - val_loss: 0.4730 - val_root_mean_squared_error: 0.6877\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "3 , Epoch 1/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 3.4338 - root_mean_squared_error: 1.8531\n",
      "Epoch 1: val_loss improved from inf to 1.07585, saving model to ./mlp/best_weights_2.hdf5\n",
      "31/31 [==============================] - 1s 11ms/step - loss: 3.3643 - root_mean_squared_error: 1.8342 - val_loss: 1.0758 - val_root_mean_squared_error: 1.0372\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0205 - root_mean_squared_error: 1.0102\n",
      "Epoch 2: val_loss improved from 1.07585 to 1.02543, saving model to ./mlp/best_weights_2.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0205 - root_mean_squared_error: 1.0102 - val_loss: 1.0254 - val_root_mean_squared_error: 1.0126\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.7346 - root_mean_squared_error: 0.8571\n",
      "Epoch 3: val_loss improved from 1.02543 to 0.68555, saving model to ./mlp/best_weights_2.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.7346 - root_mean_squared_error: 0.8571 - val_loss: 0.6856 - val_root_mean_squared_error: 0.8280\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6217 - root_mean_squared_error: 0.7885\n",
      "Epoch 4: val_loss improved from 0.68555 to 0.49986, saving model to ./mlp/best_weights_2.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6217 - root_mean_squared_error: 0.7885 - val_loss: 0.4999 - val_root_mean_squared_error: 0.7070\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4895 - root_mean_squared_error: 0.6996\n",
      "Epoch 5: val_loss did not improve from 0.49986\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4895 - root_mean_squared_error: 0.6996 - val_loss: 0.5760 - val_root_mean_squared_error: 0.7589\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4613 - root_mean_squared_error: 0.6792\n",
      "Epoch 6: val_loss improved from 0.49986 to 0.45990, saving model to ./mlp/best_weights_2.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4613 - root_mean_squared_error: 0.6792 - val_loss: 0.4599 - val_root_mean_squared_error: 0.6782\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4450 - root_mean_squared_error: 0.6671\n",
      "Epoch 7: val_loss did not improve from 0.45990\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4450 - root_mean_squared_error: 0.6671 - val_loss: 0.4680 - val_root_mean_squared_error: 0.6841\n",
      "Epoch 8/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.4639 - root_mean_squared_error: 0.6811\n",
      "Epoch 8: val_loss did not improve from 0.45990\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4662 - root_mean_squared_error: 0.6828 - val_loss: 0.4708 - val_root_mean_squared_error: 0.6862\n",
      "Epoch 9/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.4223 - root_mean_squared_error: 0.6499\n",
      "Epoch 9: val_loss did not improve from 0.45990\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4182 - root_mean_squared_error: 0.6467 - val_loss: 0.4622 - val_root_mean_squared_error: 0.6799\n",
      "Epoch 10/50\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.4088 - root_mean_squared_error: 0.6394\n",
      "Epoch 10: val_loss improved from 0.45990 to 0.43045, saving model to ./mlp/best_weights_2.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.4081 - root_mean_squared_error: 0.6388 - val_loss: 0.4304 - val_root_mean_squared_error: 0.6561\n",
      "Epoch 11/50\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.4179 - root_mean_squared_error: 0.6465\n",
      "Epoch 11: val_loss did not improve from 0.43045\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.4184 - root_mean_squared_error: 0.6469 - val_loss: 0.4382 - val_root_mean_squared_error: 0.6619\n",
      "Epoch 12/50\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.3856 - root_mean_squared_error: 0.6210\n",
      "Epoch 12: val_loss improved from 0.43045 to 0.42412, saving model to ./mlp/best_weights_2.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.3932 - root_mean_squared_error: 0.6271 - val_loss: 0.4241 - val_root_mean_squared_error: 0.6512\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3948 - root_mean_squared_error: 0.6283\n",
      "Epoch 13: val_loss did not improve from 0.42412\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3948 - root_mean_squared_error: 0.6283 - val_loss: 0.4284 - val_root_mean_squared_error: 0.6545\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3647 - root_mean_squared_error: 0.6039\n",
      "Epoch 14: val_loss did not improve from 0.42412\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3647 - root_mean_squared_error: 0.6039 - val_loss: 0.4331 - val_root_mean_squared_error: 0.6581\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3806 - root_mean_squared_error: 0.6169\n",
      "Epoch 15: val_loss improved from 0.42412 to 0.41788, saving model to ./mlp/best_weights_2.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3806 - root_mean_squared_error: 0.6169 - val_loss: 0.4179 - val_root_mean_squared_error: 0.6464\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3844 - root_mean_squared_error: 0.6200\n",
      "Epoch 16: val_loss did not improve from 0.41788\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3844 - root_mean_squared_error: 0.6200 - val_loss: 0.4308 - val_root_mean_squared_error: 0.6564\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3881 - root_mean_squared_error: 0.6229\n",
      "Epoch 17: val_loss did not improve from 0.41788\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.3881 - root_mean_squared_error: 0.6229 - val_loss: 0.4418 - val_root_mean_squared_error: 0.6647\n",
      "Epoch 18/50\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.3594 - root_mean_squared_error: 0.5995\n",
      "Epoch 18: val_loss did not improve from 0.41788\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3614 - root_mean_squared_error: 0.6012 - val_loss: 0.4304 - val_root_mean_squared_error: 0.6560\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3609 - root_mean_squared_error: 0.6007\n",
      "Epoch 19: val_loss did not improve from 0.41788\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3609 - root_mean_squared_error: 0.6007 - val_loss: 0.4347 - val_root_mean_squared_error: 0.6593\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3599 - root_mean_squared_error: 0.5999\n",
      "Epoch 20: val_loss did not improve from 0.41788\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3599 - root_mean_squared_error: 0.5999 - val_loss: 0.4950 - val_root_mean_squared_error: 0.7036\n",
      "Epoch 21/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.3774 - root_mean_squared_error: 0.6143\n",
      "Epoch 21: val_loss did not improve from 0.41788\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.3781 - root_mean_squared_error: 0.6149 - val_loss: 0.5006 - val_root_mean_squared_error: 0.7075\n",
      "Epoch 22/50\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.3756 - root_mean_squared_error: 0.6129\n",
      "Epoch 22: val_loss did not improve from 0.41788\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.3827 - root_mean_squared_error: 0.6186 - val_loss: 0.4200 - val_root_mean_squared_error: 0.6480\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3479 - root_mean_squared_error: 0.5899\n",
      "Epoch 23: val_loss did not improve from 0.41788\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3479 - root_mean_squared_error: 0.5899 - val_loss: 0.4552 - val_root_mean_squared_error: 0.6747\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3619 - root_mean_squared_error: 0.6016\n",
      "Epoch 24: val_loss did not improve from 0.41788\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3619 - root_mean_squared_error: 0.6016 - val_loss: 0.4778 - val_root_mean_squared_error: 0.6912\n",
      "Epoch 25/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.3466 - root_mean_squared_error: 0.5887\n",
      "Epoch 25: val_loss did not improve from 0.41788\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.3472 - root_mean_squared_error: 0.5892 - val_loss: 0.4486 - val_root_mean_squared_error: 0.6698\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4 , Epoch 1/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 3.4630 - root_mean_squared_error: 1.8609\n",
      "Epoch 1: val_loss improved from inf to 1.02407, saving model to ./mlp/best_weights_3.hdf5\n",
      "31/31 [==============================] - 1s 12ms/step - loss: 3.3918 - root_mean_squared_error: 1.8417 - val_loss: 1.0241 - val_root_mean_squared_error: 1.0120\n",
      "Epoch 2/50\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.9365 - root_mean_squared_error: 0.9677\n",
      "Epoch 2: val_loss improved from 1.02407 to 0.73982, saving model to ./mlp/best_weights_3.hdf5\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.9085 - root_mean_squared_error: 0.9531 - val_loss: 0.7398 - val_root_mean_squared_error: 0.8601\n",
      "Epoch 3/50\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.5796 - root_mean_squared_error: 0.7613\n",
      "Epoch 3: val_loss improved from 0.73982 to 0.48949, saving model to ./mlp/best_weights_3.hdf5\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.5787 - root_mean_squared_error: 0.7607 - val_loss: 0.4895 - val_root_mean_squared_error: 0.6996\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5312 - root_mean_squared_error: 0.7288\n",
      "Epoch 4: val_loss did not improve from 0.48949\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.5312 - root_mean_squared_error: 0.7288 - val_loss: 0.4999 - val_root_mean_squared_error: 0.7070\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4915 - root_mean_squared_error: 0.7011\n",
      "Epoch 5: val_loss improved from 0.48949 to 0.44499, saving model to ./mlp/best_weights_3.hdf5\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4915 - root_mean_squared_error: 0.7011 - val_loss: 0.4450 - val_root_mean_squared_error: 0.6671\n",
      "Epoch 6/50\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.4411 - root_mean_squared_error: 0.6642\n",
      "Epoch 6: val_loss did not improve from 0.44499\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4321 - root_mean_squared_error: 0.6573 - val_loss: 0.4636 - val_root_mean_squared_error: 0.6809\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4193 - root_mean_squared_error: 0.6475\n",
      "Epoch 7: val_loss improved from 0.44499 to 0.42548, saving model to ./mlp/best_weights_3.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4193 - root_mean_squared_error: 0.6475 - val_loss: 0.4255 - val_root_mean_squared_error: 0.6523\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4092 - root_mean_squared_error: 0.6397\n",
      "Epoch 8: val_loss did not improve from 0.42548\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4092 - root_mean_squared_error: 0.6397 - val_loss: 0.4941 - val_root_mean_squared_error: 0.7030\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4709 - root_mean_squared_error: 0.6862\n",
      "Epoch 9: val_loss improved from 0.42548 to 0.42340, saving model to ./mlp/best_weights_3.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4709 - root_mean_squared_error: 0.6862 - val_loss: 0.4234 - val_root_mean_squared_error: 0.6507\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4029 - root_mean_squared_error: 0.6348\n",
      "Epoch 10: val_loss did not improve from 0.42340\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4029 - root_mean_squared_error: 0.6348 - val_loss: 0.4700 - val_root_mean_squared_error: 0.6856\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4321 - root_mean_squared_error: 0.6574\n",
      "Epoch 11: val_loss did not improve from 0.42340\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4321 - root_mean_squared_error: 0.6574 - val_loss: 0.4252 - val_root_mean_squared_error: 0.6521\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3897 - root_mean_squared_error: 0.6242\n",
      "Epoch 12: val_loss did not improve from 0.42340\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3897 - root_mean_squared_error: 0.6242 - val_loss: 0.4368 - val_root_mean_squared_error: 0.6609\n",
      "Epoch 13/50\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.3753 - root_mean_squared_error: 0.6126\n",
      "Epoch 13: val_loss did not improve from 0.42340\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3740 - root_mean_squared_error: 0.6116 - val_loss: 0.4693 - val_root_mean_squared_error: 0.6850\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4193 - root_mean_squared_error: 0.6476\n",
      "Epoch 14: val_loss did not improve from 0.42340\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4193 - root_mean_squared_error: 0.6476 - val_loss: 0.5405 - val_root_mean_squared_error: 0.7352\n",
      "Epoch 15/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.4096 - root_mean_squared_error: 0.6400\n",
      "Epoch 15: val_loss did not improve from 0.42340\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4108 - root_mean_squared_error: 0.6410 - val_loss: 0.4333 - val_root_mean_squared_error: 0.6583\n",
      "Epoch 16/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.3609 - root_mean_squared_error: 0.6007\n",
      "Epoch 16: val_loss improved from 0.42340 to 0.41976, saving model to ./mlp/best_weights_3.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3705 - root_mean_squared_error: 0.6087 - val_loss: 0.4198 - val_root_mean_squared_error: 0.6479\n",
      "Epoch 17/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.3663 - root_mean_squared_error: 0.6052\n",
      "Epoch 17: val_loss improved from 0.41976 to 0.41957, saving model to ./mlp/best_weights_3.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3567 - root_mean_squared_error: 0.5972 - val_loss: 0.4196 - val_root_mean_squared_error: 0.6477\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3581 - root_mean_squared_error: 0.5984\n",
      "Epoch 18: val_loss did not improve from 0.41957\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3581 - root_mean_squared_error: 0.5984 - val_loss: 0.4324 - val_root_mean_squared_error: 0.6575\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3624 - root_mean_squared_error: 0.6020\n",
      "Epoch 19: val_loss improved from 0.41957 to 0.41765, saving model to ./mlp/best_weights_3.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3624 - root_mean_squared_error: 0.6020 - val_loss: 0.4176 - val_root_mean_squared_error: 0.6463\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4094 - root_mean_squared_error: 0.6399\n",
      "Epoch 20: val_loss did not improve from 0.41765\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4094 - root_mean_squared_error: 0.6399 - val_loss: 0.4232 - val_root_mean_squared_error: 0.6505\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3893 - root_mean_squared_error: 0.6239\n",
      "Epoch 21: val_loss did not improve from 0.41765\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3893 - root_mean_squared_error: 0.6239 - val_loss: 0.4340 - val_root_mean_squared_error: 0.6588\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3771 - root_mean_squared_error: 0.6141\n",
      "Epoch 22: val_loss did not improve from 0.41765\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3771 - root_mean_squared_error: 0.6141 - val_loss: 0.4395 - val_root_mean_squared_error: 0.6630\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3574 - root_mean_squared_error: 0.5978\n",
      "Epoch 23: val_loss did not improve from 0.41765\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3574 - root_mean_squared_error: 0.5978 - val_loss: 0.4466 - val_root_mean_squared_error: 0.6683\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3760 - root_mean_squared_error: 0.6132\n",
      "Epoch 24: val_loss did not improve from 0.41765\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3760 - root_mean_squared_error: 0.6132 - val_loss: 0.4731 - val_root_mean_squared_error: 0.6878\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3531 - root_mean_squared_error: 0.5942\n",
      "Epoch 25: val_loss did not improve from 0.41765\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3531 - root_mean_squared_error: 0.5942 - val_loss: 0.4199 - val_root_mean_squared_error: 0.6480\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3484 - root_mean_squared_error: 0.5903\n",
      "Epoch 26: val_loss did not improve from 0.41765\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3484 - root_mean_squared_error: 0.5903 - val_loss: 0.4328 - val_root_mean_squared_error: 0.6579\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3459 - root_mean_squared_error: 0.5882\n",
      "Epoch 27: val_loss did not improve from 0.41765\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3459 - root_mean_squared_error: 0.5882 - val_loss: 0.4364 - val_root_mean_squared_error: 0.6606\n",
      "Epoch 28/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.3573 - root_mean_squared_error: 0.5978\n",
      "Epoch 28: val_loss did not improve from 0.41765\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3549 - root_mean_squared_error: 0.5957 - val_loss: 0.4487 - val_root_mean_squared_error: 0.6698\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3594 - root_mean_squared_error: 0.5995\n",
      "Epoch 29: val_loss did not improve from 0.41765\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3594 - root_mean_squared_error: 0.5995 - val_loss: 0.4378 - val_root_mean_squared_error: 0.6616\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "5 , Epoch 1/50\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 3.7007 - root_mean_squared_error: 1.9237\n",
      "Epoch 1: val_loss improved from inf to 1.06887, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 1s 12ms/step - loss: 3.5420 - root_mean_squared_error: 1.8820 - val_loss: 1.0689 - val_root_mean_squared_error: 1.0339\n",
      "Epoch 2/50\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.9118 - root_mean_squared_error: 0.9549\n",
      "Epoch 2: val_loss improved from 1.06887 to 0.67170, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.8799 - root_mean_squared_error: 0.9380 - val_loss: 0.6717 - val_root_mean_squared_error: 0.8196\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5431 - root_mean_squared_error: 0.7369\n",
      "Epoch 3: val_loss improved from 0.67170 to 0.57476, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5431 - root_mean_squared_error: 0.7369 - val_loss: 0.5748 - val_root_mean_squared_error: 0.7581\n",
      "Epoch 4/50\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.4942 - root_mean_squared_error: 0.7030\n",
      "Epoch 4: val_loss improved from 0.57476 to 0.52246, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.4826 - root_mean_squared_error: 0.6947 - val_loss: 0.5225 - val_root_mean_squared_error: 0.7228\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4933 - root_mean_squared_error: 0.7024\n",
      "Epoch 5: val_loss did not improve from 0.52246\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4933 - root_mean_squared_error: 0.7024 - val_loss: 0.6893 - val_root_mean_squared_error: 0.8303\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4763 - root_mean_squared_error: 0.6902\n",
      "Epoch 6: val_loss improved from 0.52246 to 0.46815, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4763 - root_mean_squared_error: 0.6902 - val_loss: 0.4682 - val_root_mean_squared_error: 0.6842\n",
      "Epoch 7/50\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.4213 - root_mean_squared_error: 0.6491\n",
      "Epoch 7: val_loss improved from 0.46815 to 0.46423, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4162 - root_mean_squared_error: 0.6451 - val_loss: 0.4642 - val_root_mean_squared_error: 0.6813\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4025 - root_mean_squared_error: 0.6344\n",
      "Epoch 8: val_loss improved from 0.46423 to 0.45319, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4025 - root_mean_squared_error: 0.6344 - val_loss: 0.4532 - val_root_mean_squared_error: 0.6732\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4045 - root_mean_squared_error: 0.6360\n",
      "Epoch 9: val_loss did not improve from 0.45319\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4045 - root_mean_squared_error: 0.6360 - val_loss: 0.4561 - val_root_mean_squared_error: 0.6754\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3815 - root_mean_squared_error: 0.6176\n",
      "Epoch 10: val_loss improved from 0.45319 to 0.43612, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3815 - root_mean_squared_error: 0.6176 - val_loss: 0.4361 - val_root_mean_squared_error: 0.6604\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3873 - root_mean_squared_error: 0.6223\n",
      "Epoch 11: val_loss improved from 0.43612 to 0.42742, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3873 - root_mean_squared_error: 0.6223 - val_loss: 0.4274 - val_root_mean_squared_error: 0.6538\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4214 - root_mean_squared_error: 0.6492\n",
      "Epoch 12: val_loss did not improve from 0.42742\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4214 - root_mean_squared_error: 0.6492 - val_loss: 0.4353 - val_root_mean_squared_error: 0.6598\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3830 - root_mean_squared_error: 0.6189\n",
      "Epoch 13: val_loss did not improve from 0.42742\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3830 - root_mean_squared_error: 0.6189 - val_loss: 0.4919 - val_root_mean_squared_error: 0.7014\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3913 - root_mean_squared_error: 0.6255\n",
      "Epoch 14: val_loss did not improve from 0.42742\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3913 - root_mean_squared_error: 0.6255 - val_loss: 0.4296 - val_root_mean_squared_error: 0.6554\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4594 - root_mean_squared_error: 0.6778\n",
      "Epoch 15: val_loss did not improve from 0.42742\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4594 - root_mean_squared_error: 0.6778 - val_loss: 0.4775 - val_root_mean_squared_error: 0.6910\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3845 - root_mean_squared_error: 0.6201\n",
      "Epoch 16: val_loss did not improve from 0.42742\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3845 - root_mean_squared_error: 0.6201 - val_loss: 0.4352 - val_root_mean_squared_error: 0.6597\n",
      "Epoch 17/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.3802 - root_mean_squared_error: 0.6166\n",
      "Epoch 17: val_loss improved from 0.42742 to 0.42373, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3844 - root_mean_squared_error: 0.6200 - val_loss: 0.4237 - val_root_mean_squared_error: 0.6509\n",
      "Epoch 18/50\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.3802 - root_mean_squared_error: 0.6166\n",
      "Epoch 18: val_loss improved from 0.42373 to 0.42048, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3795 - root_mean_squared_error: 0.6160 - val_loss: 0.4205 - val_root_mean_squared_error: 0.6484\n",
      "Epoch 19/50\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.3691 - root_mean_squared_error: 0.6075\n",
      "Epoch 19: val_loss did not improve from 0.42048\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3707 - root_mean_squared_error: 0.6088 - val_loss: 0.4234 - val_root_mean_squared_error: 0.6507\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3876 - root_mean_squared_error: 0.6226\n",
      "Epoch 20: val_loss did not improve from 0.42048\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3876 - root_mean_squared_error: 0.6226 - val_loss: 0.4352 - val_root_mean_squared_error: 0.6597\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3578 - root_mean_squared_error: 0.5982\n",
      "Epoch 21: val_loss did not improve from 0.42048\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3578 - root_mean_squared_error: 0.5982 - val_loss: 0.4289 - val_root_mean_squared_error: 0.6549\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3703 - root_mean_squared_error: 0.6085\n",
      "Epoch 22: val_loss improved from 0.42048 to 0.41563, saving model to ./mlp/best_weights_4.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3703 - root_mean_squared_error: 0.6085 - val_loss: 0.4156 - val_root_mean_squared_error: 0.6447\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3534 - root_mean_squared_error: 0.5945\n",
      "Epoch 23: val_loss did not improve from 0.41563\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3534 - root_mean_squared_error: 0.5945 - val_loss: 0.4213 - val_root_mean_squared_error: 0.6491\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4048 - root_mean_squared_error: 0.6363\n",
      "Epoch 24: val_loss did not improve from 0.41563\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4048 - root_mean_squared_error: 0.6363 - val_loss: 0.4841 - val_root_mean_squared_error: 0.6958\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3659 - root_mean_squared_error: 0.6049\n",
      "Epoch 25: val_loss did not improve from 0.41563\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3659 - root_mean_squared_error: 0.6049 - val_loss: 0.4252 - val_root_mean_squared_error: 0.6520\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3720 - root_mean_squared_error: 0.6099\n",
      "Epoch 26: val_loss did not improve from 0.41563\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3720 - root_mean_squared_error: 0.6099 - val_loss: 0.4237 - val_root_mean_squared_error: 0.6509\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3497 - root_mean_squared_error: 0.5913\n",
      "Epoch 27: val_loss did not improve from 0.41563\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3497 - root_mean_squared_error: 0.5913 - val_loss: 0.4226 - val_root_mean_squared_error: 0.6501\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3501 - root_mean_squared_error: 0.5917\n",
      "Epoch 28: val_loss did not improve from 0.41563\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3501 - root_mean_squared_error: 0.5917 - val_loss: 0.4343 - val_root_mean_squared_error: 0.6590\n",
      "Epoch 29/50\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.3606 - root_mean_squared_error: 0.6005\n",
      "Epoch 29: val_loss did not improve from 0.41563\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3637 - root_mean_squared_error: 0.6031 - val_loss: 0.5610 - val_root_mean_squared_error: 0.7490\n",
      "Epoch 30/50\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.3690 - root_mean_squared_error: 0.6075\n",
      "Epoch 30: val_loss did not improve from 0.41563\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3723 - root_mean_squared_error: 0.6101 - val_loss: 0.4196 - val_root_mean_squared_error: 0.6478\n",
      "Epoch 31/50\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.3455 - root_mean_squared_error: 0.5878\n",
      "Epoch 31: val_loss did not improve from 0.41563\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.3424 - root_mean_squared_error: 0.5852 - val_loss: 0.4228 - val_root_mean_squared_error: 0.6502\n",
      "Epoch 32/50\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.3454 - root_mean_squared_error: 0.5877\n",
      "Epoch 32: val_loss did not improve from 0.41563\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.3399 - root_mean_squared_error: 0.5830 - val_loss: 0.4364 - val_root_mean_squared_error: 0.6606\n",
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=10,\n",
    "                                                    mode='min')\n",
    "\n",
    "\n",
    "target_name = 'score'\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X=df, y=df.score*10,)):\n",
    "     # TRAIN DATA\n",
    "    best_weights_filepath = f'./mlp/best_weights_{i}.hdf5'\n",
    "    earlyStopping=tf.keras.callbacks.ModelCheckpoint(best_weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "    train_x = df.iloc[train_index][FEATURES]\n",
    "    train_users = train_x.index.values\n",
    "    train_y = df[[target_name]].iloc[train_index]\n",
    "\n",
    "    # VALID DATA\n",
    "    valid_x = df.iloc[test_index][FEATURES]\n",
    "    valid_users = valid_x.index.values\n",
    "    valid_y = df[[target_name]].iloc[test_index]\n",
    "\n",
    "    print(i+1, ', ', end='')\n",
    "    clf = create_ae_mlp(num_columns=len(FEATURES), hidden_units=[256,512,1024,1024,512,256], lr = 1e-3)\n",
    "    #best_iteration_xgb[str(i)].append(clf.best_ntree_limit)\n",
    "\n",
    "    history = clf.fit(train_x.astype('float32').values, train_y[target_name].values, epochs=50,\n",
    "                      validation_data=(valid_x.astype('float32').values, valid_y[target_name].values),\n",
    "                      callbacks=[early_stopping,earlyStopping],\n",
    "                     batch_size=64,\n",
    "                     )\n",
    "    clf.load_weights(best_weights_filepath)\n",
    "    oof_xgb.loc[valid_users, 'mlp'] = clf.predict(valid_x.astype('float32').values)\n",
    "   \n",
    "    # clf = TabNetRegressor()  #TabNetRegressor()\n",
    "    # train_x = train_x.fillna(0)\n",
    "    # valid_x = valid_x.fillna(0)\n",
    "    # clf.fit(\n",
    "    #   train_x.values , train_y.values,\n",
    "    #   eval_set=[(valid_x.values, valid_y.values)],\n",
    "    #   eval_metric=['rmse']\n",
    "    # )\n",
    "    \n",
    "    #oof_xgb.loc[valid_users, 'predict'] = clf.predict(valid_x.values)[:,0]\n",
    "    \n",
    "final_result = oof_xgb.join(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f81b9b60-80f0-4d8c-9b19-bb5e2113dd8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6477864066578247"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(final_result['score'], final_result['mlp'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "924ad00f-0673-48b2-b393-c066f80c6188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6475833321892487"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(final_result['score'], final_result['mlp'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa49abfa-d098-4cb8-bde6-5462347de83f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: mlp/ (stored 0%)\n",
      "updating: mlp/best_weights_3.hdf5 (deflated 7%)\n",
      "updating: mlp/.ipynb_checkpoints/ (stored 0%)\n",
      "updating: mlp/best_weights_2.hdf5 (deflated 7%)\n",
      "updating: mlp/best_weights_4.hdf5 (deflated 7%)\n",
      "updating: mlp/best_weights_1.hdf5 (deflated 7%)\n",
      "updating: mlp/best_weights_0.hdf5 (deflated 7%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r mlp.zip mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b540a9b8-7707-4215-90b2-9085b725a2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0.6381 BASELINE - v1\n",
    "# 0.6372807396907196 remving up event\n",
    "# 0.6363905859568488 adding every_word_count with up event\n",
    "# 0.6388692848476841 adding every_word_count without up event\n",
    "# 0.6375898226286834 removing every_word_count with up event + word_count_pre_step\n",
    "# 0.634864097139824 -v4\n",
    "# 0.6324737799704642 adding every_char_word\n",
    "# 0.6312740919756227 adding every_char_word & every_sentence_change\n",
    "# 0.6301625913548855 - v9\n",
    "# 0.624126755429523 -v17\n",
    "# 0.6228860242274676 -v19\n",
    "# cv 0.616 lb 0.602 -v28\n",
    "# cv 0.6159972729277812 lb 0.601 -v29"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
